# Patch generated by Pyment v0.3.3

--- a/mnist.py
+++ b/mnist.py
@@ -44,7 +44,23 @@
 def dataset_partitioner(
     dataset: Dataset, batch_size: int, client_id: int, number_of_clients: int
 ) -> DataLoader:
-    """ Helper function to partition datasets"""
+    """Helper function to partition datasets
+
+    Parameters
+    ----------
+    dataset: Dataset :
+        
+    batch_size: int :
+        
+    client_id: int :
+        
+    number_of_clients: int :
+        
+
+    Returns
+    -------
+
+    """
 
     # Set the seed so we are sure to generate the same global batches
     # indices across all clients
@@ -73,7 +89,25 @@
     cid: int,
     nb_clients: int,
 ) -> Tuple[DataLoader, DataLoader]:
-    """ Helper function to load MNIST datasets"""
+    """Helper function to load MNIST datasets
+
+    Parameters
+    ----------
+    data_root: str :
+        
+    train_batch_size: int :
+        
+    test_batch_size: int :
+        
+    cid: int :
+        
+    nb_clients: int :
+        
+
+    Returns
+    -------
+
+    """
 
     transform = transforms.Compose(
         [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]
@@ -116,7 +150,17 @@
 
     # pylint: disable-msg=arguments-differ,invalid-name
     def forward(self, x: Tensor) -> Tensor:
-        """Compute forward pass."""
+        """Compute forward pass.
+
+        Parameters
+        ----------
+        x: Tensor :
+            
+
+        Returns
+        -------
+
+        """
         x = self.conv1(x)
         x = F.relu(x)
         x = self.conv2(x)
@@ -138,7 +182,23 @@
     epochs: int,
     device: torch.device = torch.device("cpu"),
 ) -> int:
-    """Train routine based on 'Basic MNIST Example'"""
+    """Train routine based on 'Basic MNIST Example'
+
+    Parameters
+    ----------
+    model: torch.nn.ModuleList :
+        
+    train_loader: torch.utils.data.DataLoader :
+        
+    epochs: int :
+        
+    device: torch.device :
+         (Default value = torch.device("cpu"))
+
+    Returns
+    -------
+
+    """
     model.train()
     optimizer = optim.Adadelta(model.parameters(), lr=1.0)
     #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
@@ -186,7 +246,21 @@
     test_loader: torch.utils.data.DataLoader,
     device: torch.device = torch.device("cpu"),
 ) -> Tuple[int, float, float]:
-    """Test routine 'Basic MNIST Example'"""
+    """Test routine 'Basic MNIST Example'
+
+    Parameters
+    ----------
+    model: torch.nn.ModuleList :
+        
+    test_loader: torch.utils.data.DataLoader :
+        
+    device: torch.device :
+         (Default value = torch.device("cpu"))
+
+    Returns
+    -------
+
+    """
     model.eval()
     test_loss: float = 0
     correct: int = 0
@@ -232,7 +306,17 @@
         return [val.cpu().numpy() for _, val in self.model.state_dict().items()]
 
     def set_weights(self, weights: fl.common.Weights) -> None:
-        """Set model weights from a list of NumPy ndarrays."""
+        """Set model weights from a list of NumPy ndarrays.
+
+        Parameters
+        ----------
+        weights: fl.common.Weights :
+            
+
+        Returns
+        -------
+
+        """
         state_dict = OrderedDict(
             {
                 k: torch.Tensor(v)
@@ -242,11 +326,23 @@
         self.model.load_state_dict(state_dict, strict=True)
 
     def get_parameters(self) -> fl.common.ParametersRes:
+        """ """
         weights: fl.common.Weights = self.get_weights()
         parameters = fl.common.weights_to_parameters(weights)
         return fl.common.ParametersRes(parameters=parameters)
 
     def fit(self, ins: fl.common.FitIns) -> fl.common.FitRes:
+        """
+
+        Parameters
+        ----------
+        ins: fl.common.FitIns :
+            
+
+        Returns
+        -------
+
+        """
 
         # Set the seed so we are sure to generate the same global batches
         # indices across all clients
@@ -275,6 +371,17 @@
         )
 
     def evaluate(self, ins: fl.common.EvaluateIns) -> fl.common.EvaluateRes:
+        """
+
+        Parameters
+        ----------
+        ins: fl.common.EvaluateIns :
+            
+
+        Returns
+        -------
+
+        """
 
         # Set the set so we are sure to generate the same batches
         # accross all clients.
